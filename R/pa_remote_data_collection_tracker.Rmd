---
title: 'UNHCR PA: Data Collection Tracker'
author: "REACH"
date: "2022-11-08"
output:  
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = paste0(dirname(inputFile), '/pa_field_data_collection_tracker_', format(Sys.Date(), '%Y_%m_%d'),'.html')) })
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

# read packages
library(tidyverse)
library(lubridate)
library(glue)
library(leaflet)

source("../R/support_functions.R")

df_logical_check_description <- readr::read_csv("../inputs/PA_Logical_checks_overview.csv") %>% 
  janitor::clean_names() %>% 
  select(check_number, check_description) %>% 
  mutate(check_number = as.character(check_number))

df_refugee_samples <- readr::read_csv("../inputs/Refugee_PA_survey_samples_definition.csv")
  
df_for_colnames <- df_refugee_samples %>% 
  mutate(settlement = str_to_lower(settlement))%>% 
  select(settlement) %>% 
  unique()

df_refugee_samples_required <- df_refugee_samples %>% 
  select(settlement, sample_size) %>% 
  mutate(settlement = str_to_lower(settlement))


df_tool_data <- readxl::read_excel("../inputs/partipatory_assessment_data.xlsx") %>% 
  mutate(uuid = `_uuid`,
         start_date = as_date(start),
         start = as_datetime(start),
         end = as_datetime(end),
         settlement = str_to_lower(settlement)) %>% 
  filter(start_date  > as_date("2022-11-22") & end_result == 1)
 

# reading data for complete plus incomplete surveys
df_phone_data_unfiltered <- readxl::read_excel("../inputs/partipatory_assessment_data.xlsx") %>% 
  mutate(uuid = `_uuid`,
         start_date = as_date(start),
         start = as_datetime(start),
         end = as_datetime(end),
         settlement = str_to_lower(settlement)) %>% 
  filter(start_date  > as_date("2022-11-22"))


# days that contain data
df_days_for_data_collection <- df_tool_data %>% select(start_date) %>% unique() %>% arrange(start_date) %>% pull()

df_data_support_cl_log <- df_tool_data %>% 
  select(uuid, status)
# cleaning log handling
df_cl_log <- read_csv(file = "../inputs/combined_checks_PA.csv") %>% 
  mutate(adjust_log = ifelse(is.na(adjust_log), "apply_suggested_change", adjust_log)) %>% 
  left_join(df_data_support_cl_log, by = "uuid")

# change_response logs that affect stats in the data collection progress
cl_log_change_response <- df_cl_log %>% 
  filter(type == "change_response", 
         !is.na(value),
         reviewed == 1, 
         adjust_log != "delete_log", 
        ) %>% 
  select(uuid, name, value)

# updated tool data
df_updated_tool_data <- df_tool_data

# get uuids from cleaning log
uuids_chg_response <- cl_log_change_response %>% pull(uuid) %>% unique()

for (current_uuid in uuids_chg_response) {
  current_uuid_data <- cl_log_change_response %>% 
    filter(uuid == current_uuid) %>% 
    mutate(value = ifelse(name == "enumerator_id", as.numeric(value), value)) %>% 
    pivot_wider(names_from = "name", values_from = "value", uuid)
  print(current_uuid_data)
  # process current updates
  df_current_updated <- df_updated_tool_data %>% 
    rows_update(y = current_uuid_data, by = "uuid")
  # update the parent dataset with current updates
  df_updated_tool_data <- df_current_updated
}

# enumerator performance data
df_enum_performance <- df_updated_tool_data %>% 
  mutate(int.survey_time_interval = lubridate::time_length(end - start, unit = "min"),
         int.survey_time_interval = ceiling(int.survey_time_interval))

# functions for changing some options in the table
dt_with_modified_options <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  columnDefs = list(list(className = 'dt-center', targets = list(1,2,3,4,5))),
                  pageLength = 20,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}")
                )
  )
}

dt_options_fewcols <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  pageLength = 20,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}")
                )
  )
}


dt_enum_performance_options <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                filter = 'top',
                options = list(
                  columnDefs = list(list(className = 'dt-center', targets = list(1,2))),
                  pageLength = 50,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}"),
                  order = list(list(1, 'desc'), list(0, 'asc'), list(3, 'desc'))
                )
  )
}


## Summary on the surveys done

>There are *`r nrow(df_updated_tool_data)`* total number of surveys done as of *`r df_days_for_data_collection[length(df_days_for_data_collection)]`*.

>The average survey time for all the data is: *`r get_average_survey_time(df_updated_tool_data)`* Minutes

### General outlook

{r, echo = FALSE}
df_modified_data <- df_updated_tool_data %>% 
  mutate(settlement = paste0(settlement, "_", settlement)) %>% 
  group_by(settlement, start_date) %>% 
  arrange(settlement, desc(start_date)) %>% 
  summarise(number_of_surveys = n()) 

# chart
ggplot(data = df_modified_data, aes(x = start_date, y = number_of_surveys, color = settlement)) +
  geom_line(size=0.8, alpha=0.9) +
  geom_point()+
  labs(x = "",
       y = "Number of surveys", 
       title = "Number of surveys per location")+
  scale_x_date(date_labels = "%d/%b/%Y")+
  theme_bw()


### Settlements:  *`r df_updated_tool_data %>% filter(status == "refugee") %>% nrow()`* surveys

{r, echo = FALSE}
df_refugee_samp_per_settlement <- df_refugee_samples_required %>% 
  group_by(settlement) %>% 
  summarise(required_samples = sum(sample_size, na.rm = TRUE))

df_cl_surveys_for_deletion <- df_cl_log %>% 
  filter(status == "refugee", type == "remove_survey", reviewed == 1, adjust_log != "delete_log") %>%
  group_by(settlement) %>% 
  distinct(uuid) %>%
  summarise(surveys_for_deletion = n())

df_updated_tool_data %>% 
  filter(status == "refugee") %>% 
  group_by(settlement) %>% 
  summarise(number_of_surveys = n()) %>% 
  arrange(settlement) %>% 
  right_join(df_refugee_samp_per_settlement, by = "settlement") %>% 
  left_join(df_cl_surveys_for_deletion, by = "settlement") %>% 
  mutate(number_of_surveys = ifelse(is.na(number_of_surveys), 0, number_of_surveys),
         surveys_for_deletion = ifelse(is.na(surveys_for_deletion), 0, surveys_for_deletion),
         int.surveys_and_deletion = number_of_surveys - surveys_for_deletion,
         remaining_surveys = required_samples - int.surveys_and_deletion ) %>% 
  left_join(df_for_colnames, by = "settlement") %>% 
  select(-c(int.surveys_and_deletion)) %>%
  dt_with_modified_options()



### Phone calls statistics

{r, echo = FALSE}

df_numbers_called <- df_phone_data_unfiltered %>% 
  distinct(number, start_date, .keep_all = TRUE) %>%
  select(start_date, number) %>% 
  group_by(start_date) %>% 
  summarise(
    unique_numbers_called = n()
    # total_unique_numbers_recalled = total_unique_numbers_called - nrow(-lag(start_date))
  )
df_numbers_called %>% 
  DT::datatable()



### Daily enumerator performance

{r, echo = FALSE}
df_enum_performance %>% 
  group_by(settlement, start_date, enumerator_id) %>% 
  summarise(number_of_interviews_done = n(), `average_survey_time(minutes)` = round(mean(int.survey_time_interval, na.rm = TRUE), 0)) %>% 
  dt_enum_performance_options()


## Looking into the cleaning log

### Number of issues by issue_id

{r, echo = FALSE}
df_cl_log %>% 
  group_by(enumerator_id, issue_id, issue) %>% 
  summarise(number_of_issues_by_issue_id = n()) %>%
  mutate(int.issue_id = str_extract(string = issue_id, pattern = "[0-9]{1,3}")) %>% 
  left_join(df_logical_check_description, by = c("int.issue_id" = "check_number")) %>% 
  mutate(issue = ifelse(str_detect(string = issue_id, pattern = "[0-9]{1,3}"), paste(check_description, "[ ", issue, " ]"), issue)) %>% 
  select(-c(int.issue_id, check_description)) %>% 
  dt_options_fewcols()


### Number of issues by enumerator

{r, echo = FALSE}
df_cl_log %>% 
  group_by(settlement, enumerator_id) %>% 
  summarise(number_of_issues_by_enumerator_id = n()) %>%
  dt_options_fewcols()


### Number of issues by enumerator and issue_id

{r, echo = FALSE}
df_cl_log %>% 
  group_by(issue_id) %>% 
  summarise(number_of_issues_by_enumerator_and_issue_id = n()) %>%
  mutate(int.issue_id = str_extract(string = issue_id, pattern = "[0-9]{1,3}")) %>% 
  left_join(df_logical_check_description, by = c("int.issue_id" = "check_number")) %>% 
  mutate(check_description = ifelse(str_detect(string = issue_id, pattern = "[0-9]{1,3}"), check_description, issue_id)) %>% 
  select(-c(int.issue_id)) %>%
  dt_options_fewcols()


### Enumerators with surveys for deletion

{r, echo = FALSE}

df_enum_n_surveys <- df_updated_tool_data %>% 
  group_by(settlement, enumerator_id) %>% 
  summarise(no_surveys = n())

df_cl_log %>% 
  filter(type == "remove_survey", reviewed == 1, adjust_log != "delete_log") %>% 
  group_by(settlement, enumerator_id) %>% 
  summarise(number_of_surveys_for_deletion_by_enumerator = n()) %>%
  arrange(desc(number_of_surveys_for_deletion_by_enumerator)) %>%
  left_join(df_enum_n_surveys, by = "enumerator_id") %>% 
  rename(settlement = settlement.x) %>% 
  select(-c(settlement.y)) %>% 
  mutate(`% of deletion` = round((number_of_surveys_for_deletion_by_enumerator/ no_surveys)*100, 0)) %>% 
  dt_options_fewcols()

```



